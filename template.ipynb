{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template for the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sae_lens import HookedSAETransformer, SAE, SAEConfig\n",
    "from gemma_utils import get_gemma_2_config, gemma_2_sae_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "import einops\n",
    "import re\n",
    "from jaxtyping import Int, Float\n",
    "from typing import List, Optional, Any\n",
    "from torch import Tensor\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from transformer_lens.utils import get_act_name\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb28583091843908d3ff529b5b95f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"google/gemma-2-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cities = [\n",
    "    \"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \n",
    "    \"San Francisco\", \"Miami\", \"Dallas\", \"Boston\", \"Seattle\",\n",
    "    \"Atlanta\", \"Denver\", \"San Diego\", \"Las Vegas\", \"Washington D.C.\",\n",
    "    \"Orlando\", \"Philadelphia\", \"Austin\", \"San Antonio\", \"Charlotte\",\n",
    "    \"Portland\", \"Salt Lake City\", \"Minneapolis\", \"Detroit\", \"Nashville\",\n",
    "    \"Cleveland\", \"Kansas City\", \"Indianapolis\", \"Columbus\", \"Memphis\",\n",
    "    \"Baltimore\", \"Milwaukee\", \"Sacramento\", \"New Orleans\", \"Tampa\",\n",
    "    \"Pittsburgh\", \"Cincinnati\", \"St. Louis\", \"Raleigh\", \"Richmond\",\n",
    "    \"Oklahoma City\", \"Albuquerque\", \"Tucson\", \"Honolulu\", \"Anchorage\",\n",
    "    \"Fort Worth\", \"El Paso\", \"Birmingham\", \"Louisville\", \"Buffalo\"\n",
    "]\n",
    "\n",
    "token_cities = model.tokenizer(cities, add_special_tokens=False)['input_ids']\n",
    "single_token_cities = [tok for tok in token_cities if len(tok)==1]\n",
    "cities = [model.tokenizer.decode(tok) for tok in single_token_cities]\n",
    "def get_template(city1,city2,city3):\n",
    "    string = f\"A list of my brother's favourite cities are:\\n- {city1}\\n- {city2}\\n- {city3}\\n\"\n",
    "    return string\n",
    "all_strings = []\n",
    "for i in range(len(cities)):\n",
    "    for j in range(i+1,len(cities)):\n",
    "        for k in range(j+1,len(cities)):\n",
    "            city1 = cities[i]\n",
    "            city2 = cities[j]\n",
    "            city3 = cities[k]\n",
    "            string = get_template(city1,city2,city3)\n",
    "            all_strings.append(string)\n",
    "\n",
    "tokens = model.tokenizer(all_strings, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature-circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
